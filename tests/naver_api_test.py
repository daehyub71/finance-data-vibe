"""
ë„¤ì´ë²„ ë‰´ìŠ¤ API ì—°ë™ í…ŒìŠ¤íŠ¸
1. API ì—°ê²° í™•ì¸
2. ì‚¼ì„±ì „ì ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
3. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™
"""

import requests
import sqlite3
import pandas as pd
import time
from datetime import datetime, timedelta
import logging
from typing import List, Dict, Optional
import os
import json
import re
from bs4 import BeautifulSoup

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class NaverNewsAPITest:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        self.headers = {
            'X-Naver-Client-Id': self.client_id,
            'X-Naver-Client-Secret': self.client_secret
        }
        
    def test_connection(self) -> bool:
        """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
        logger.info("ğŸ”— ë„¤ì´ë²„ ë‰´ìŠ¤ API ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        params = {
            'query': 'ì‚¼ì„±ì „ì',
            'display': 1,
            'sort': 'date'
        }
        
        try:
            response = requests.get(self.base_url, headers=self.headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            
            if 'items' in data:
                logger.info("âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ API ì—°ê²° ì„±ê³µ!")
                logger.info(f"ğŸ“Š API ì‘ë‹µ: {len(data['items'])}ê°œ ë‰´ìŠ¤ ê²€ìƒ‰ë¨")
                logger.info(f"ğŸ”¢ ì „ì²´ ê²€ìƒ‰ ê²°ê³¼: {data.get('total', 0):,}ê°œ")
                return True
            else:
                logger.error("âŒ API ì‘ë‹µì— ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return False
                
        except requests.exceptions.HTTPError as e:
            if response.status_code == 401:
                logger.error("âŒ ì¸ì¦ ì‹¤íŒ¨: Client ID ë˜ëŠ” Secretì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
            elif response.status_code == 403:
                logger.error("âŒ ê¶Œí•œ ì—†ìŒ: ê²€ìƒ‰ APIê°€ í™œì„±í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            else:
                logger.error(f"âŒ HTTP ì˜¤ë¥˜: {e}")
            return False
            
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def search_news_detailed(self, query: str, display: int = 10) -> Dict:
        """ìƒì„¸ ë‰´ìŠ¤ ê²€ìƒ‰ (ë¶„ì„ìš©)"""
        logger.info(f"ğŸ” '{query}' ê²€ìƒ‰ ì¤‘...")
        
        params = {
            'query': query,
            'display': display,
            'sort': 'date'
        }
        
        try:
            response = requests.get(self.base_url, headers=self.headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            items = data.get('items', [])
            
            # ë‰´ìŠ¤ ë¶„ì„
            analysis = {
                'total_results': data.get('total', 0),
                'returned_count': len(items),
                'news_items': [],
                'sources': {},
                'recent_news': []
            }
            
            for item in items:
                # HTML íƒœê·¸ ì œê±°
                title = re.sub(r'<[^>]+>', '', item['title'])
                description = re.sub(r'<[^>]+>', '', item['description'])
                
                # ë‰´ìŠ¤ ì†ŒìŠ¤ ë¶„ì„
                if 'originallink' in item:
                    source = self._extract_source(item['originallink'])
                    analysis['sources'][source] = analysis['sources'].get(source, 0) + 1
                
                news_item = {
                    'title': title,
                    'description': description,
                    'link': item['link'],
                    'pub_date': item['pubDate'],
                    'source': self._extract_source(item.get('originallink', ''))
                }
                
                analysis['news_items'].append(news_item)
                
                # ìµœê·¼ 24ì‹œê°„ ë‰´ìŠ¤ ì²´í¬
                pub_date = self._parse_date(item['pubDate'])
                if pub_date and (datetime.now() - pub_date).days < 1:
                    analysis['recent_news'].append(news_item)
            
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {}
    
    def _extract_source(self, url: str) -> str:
        """URLì—ì„œ ë‰´ìŠ¤ ì†ŒìŠ¤ ì¶”ì¶œ"""
        if not url:
            return 'Unknown'
            
        if 'naver.com' in url:
            return 'Naver'
        elif 'chosun.com' in url:
            return 'ì¡°ì„ ì¼ë³´'
        elif 'donga.com' in url:
            return 'ë™ì•„ì¼ë³´'
        elif 'joins.com' in url:
            return 'ì¤‘ì•™ì¼ë³´'
        elif 'hani.co.kr' in url:
            return 'í•œê²¨ë ˆ'
        elif 'khan.co.kr' in url:
            return 'ê²½í–¥ì‹ ë¬¸'
        elif 'mk.co.kr' in url:
            return 'ë§¤ì¼ê²½ì œ'
        elif 'hankyung.com' in url:
            return 'í•œêµ­ê²½ì œ'
        elif 'etnews.com' in url:
            return 'ì „ìì‹ ë¬¸'
        elif 'yonhapnews.co.kr' in url:
            return 'ì—°í•©ë‰´ìŠ¤'
        else:
            # ë„ë©”ì¸ì—ì„œ ì¶”ì¶œ
            try:
                domain = url.split('//')[1].split('/')[0].split('.')
                return domain[-2] if len(domain) > 1 else 'Unknown'
            except:
                return 'Unknown'
    
    def _parse_date(self, date_str: str) -> Optional[datetime]:
        """ë‚ ì§œ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜"""
        try:
            # RFC 2822 í˜•ì‹: "Sat, 05 Jul 2025 14:30:00 +0900"
            dt = datetime.strptime(date_str, "%a, %d %b %Y %H:%M:%S %z")
            # timezone ì •ë³´ ì œê±°í•˜ì—¬ naive datetimeìœ¼ë¡œ ë³€í™˜
            return dt.replace(tzinfo=None)
        except:
            try:
                # ë‹¤ë¥¸ í˜•ì‹ ì‹œë„
                return datetime.strptime(date_str, "%Y-%m-%d %H:%M:%S")
            except:
                return None
    
    def collect_content(self, url: str) -> str:
        """ë‰´ìŠ¤ ë³¸ë¬¸ ìˆ˜ì§‘"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë„¤ì´ë²„ ë‰´ìŠ¤ì¸ ê²½ìš°
            if 'news.naver.com' in url:
                content_div = soup.find('div', {'id': 'newsct_article'}) or \
                             soup.find('div', {'class': 'newsct_article'}) or \
                             soup.find('div', {'id': 'articleBodyContents'})
                             
                if content_div:
                    # ê´‘ê³ , ìŠ¤í¬ë¦½íŠ¸ ë“± ì œê±°
                    for elem in content_div.find_all(['script', 'style', 'ins', 'iframe']):
                        elem.decompose()
                    
                    text = content_div.get_text(strip=True)
                    # ë¶ˆí•„ìš”í•œ ë¬¸êµ¬ ì œê±°
                    text = re.sub(r'(// flash ì˜¤ë¥˜ë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•œ í•¨ìˆ˜ ì¶”ê°€.*)', '', text)
                    text = re.sub(r'\s+', ' ', text)  # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
                    
                    return text[:1000]  # ìµœëŒ€ 1000ìë¡œ ì œí•œ
            
            return "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"
            
        except Exception as e:
            logger.warning(f"ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨ - URL: {url}, ì˜¤ë¥˜: {e}")
            return "ë³¸ë¬¸ ìˆ˜ì§‘ ì‹¤íŒ¨"

def test_existing_database():
    """ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ—„ï¸ ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸...")
    
    db_path = "finance_data.db"
    
    if not os.path.exists(db_path):
        logger.warning(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {db_path}")
        logger.info("ğŸ”§ ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        
        # ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
        create_basic_database()
        return get_sample_stocks()
    
    try:
        with sqlite3.connect(db_path) as conn:
            # ê¸°ì¡´ í…Œì´ë¸” í™•ì¸
            cursor = conn.cursor()
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ!")
            logger.info(f"ğŸ“Š ê¸°ì¡´ í…Œì´ë¸”: {', '.join(tables)}")
            
            # ì¢…ëª© ë°ì´í„° í™•ì¸
            if 'stock_info' in tables:
                stock_count = pd.read_sql_query(
                    "SELECT COUNT(*) as count FROM stock_info", conn
                ).iloc[0]['count']
                logger.info(f"ğŸ“ˆ ë“±ë¡ëœ ì¢…ëª© ìˆ˜: {stock_count:,}ê°œ")
                
                # ìƒ˜í”Œ ì¢…ëª© ì¡°íšŒ
                sample_stocks = pd.read_sql_query(
                    "SELECT code, name FROM stock_info LIMIT 5", conn
                )
                logger.info("ğŸ“‹ ìƒ˜í”Œ ì¢…ëª©:")
                for _, stock in sample_stocks.iterrows():
                    logger.info(f"  â€¢ {stock['name']}({stock['code']})")
                
                return sample_stocks.to_dict('records')
            else:
                logger.warning("âš ï¸ stock_info í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì¢…ëª©ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                create_basic_stocks()
                return get_sample_stocks()
                
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def create_basic_database():
    """ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ìƒì„±"""
    db_path = "finance_data.db"
    
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        # ê¸°ë³¸ í…Œì´ë¸”ë“¤ ìƒì„±
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS stock_info (
                code TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                market TEXT,
                sector TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS stock_prices (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                code TEXT NOT NULL,
                date TEXT NOT NULL,
                open_price REAL,
                high_price REAL,
                low_price REAL,
                close_price REAL,
                volume INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (code) REFERENCES stock_info (code),
                UNIQUE(code, date)
            )
        ''')
        
        conn.commit()
    
    logger.info("âœ… ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° ìƒì„± ì™„ë£Œ")

def create_basic_stocks():
    """ê¸°ë³¸ ì¢…ëª© ë°ì´í„° ì‚½ì…"""
    db_path = "finance_data.db"
    
    # ì£¼ìš” ì¢…ëª©ë“¤
    basic_stocks = [
        ('005930', 'ì‚¼ì„±ì „ì', 'KOSPI', 'IT'),
        ('000660', 'SKí•˜ì´ë‹‰ìŠ¤', 'KOSPI', 'IT'),
        ('035420', 'NAVER', 'KOSPI', 'IT'),
        ('005380', 'í˜„ëŒ€ì°¨', 'KOSPI', 'ìë™ì°¨'),
        ('006400', 'ì‚¼ì„±SDI', 'KOSPI', 'í™”í•™'),
        ('051910', 'LGí™”í•™', 'KOSPI', 'í™”í•™'),
        ('096770', 'SKì´ë…¸ë² ì´ì…˜', 'KOSPI', 'í™”í•™'),
        ('034730', 'SK', 'KOSPI', 'ì§€ì£¼íšŒì‚¬'),
        ('003550', 'LG', 'KOSPI', 'ì§€ì£¼íšŒì‚¬'),
        ('012330', 'í˜„ëŒ€ëª¨ë¹„ìŠ¤', 'KOSPI', 'ìë™ì°¨ë¶€í’ˆ')
    ]
    
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        for stock in basic_stocks:
            cursor.execute('''
                INSERT OR IGNORE INTO stock_info (code, name, market, sector)
                VALUES (?, ?, ?, ?)
            ''', stock)
        
        conn.commit()
    
    logger.info(f"âœ… {len(basic_stocks)}ê°œ ê¸°ë³¸ ì¢…ëª© ë°ì´í„° ìƒì„± ì™„ë£Œ")

def get_sample_stocks():
    """ìƒ˜í”Œ ì¢…ëª© ë°˜í™˜"""
    return [
        {'code': '005930', 'name': 'ì‚¼ì„±ì „ì'},
        {'code': '000660', 'name': 'SKí•˜ì´ë‹‰ìŠ¤'},
        {'code': '035420', 'name': 'NAVER'},
        {'code': '005380', 'name': 'í˜„ëŒ€ì°¨'},
        {'code': '006400', 'name': 'ì‚¼ì„±SDI'}
    ]

def create_news_table():
    """ë‰´ìŠ¤ í…Œì´ë¸” ìƒì„±"""
    logger.info("ğŸ“° ë‰´ìŠ¤ í…Œì´ë¸” ìƒì„± ì¤‘...")
    
    db_path = "finance_data.db"
    
    with sqlite3.connect(db_path) as conn:
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS news_articles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                stock_code TEXT NOT NULL,
                stock_name TEXT NOT NULL,
                title TEXT NOT NULL,
                link TEXT NOT NULL UNIQUE,
                description TEXT,
                content TEXT,
                pub_date TEXT,
                source TEXT,
                sentiment_score REAL DEFAULT 0.0,
                collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_stock_code ON news_articles(stock_code)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_pub_date ON news_articles(pub_date)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_collected_at ON news_articles(collected_at)')
        
        conn.commit()
        
    logger.info("âœ… ë‰´ìŠ¤ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")

def test_news_collection(api: NaverNewsAPITest, stock_code: str = "005930", stock_name: str = "ì‚¼ì„±ì „ì"):
    """ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸"""
    logger.info(f"ğŸ“° {stock_name}({stock_code}) ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸...")
    
    # ë‰´ìŠ¤ ê²€ìƒ‰
    analysis = api.search_news_detailed(stock_name, display=5)
    
    if not analysis:
        logger.error("âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨")
        return
    
    logger.info(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼:")
    logger.info(f"  â€¢ ì „ì²´ ê²°ê³¼: {analysis['total_results']:,}ê°œ")
    logger.info(f"  â€¢ ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {analysis['returned_count']}ê°œ")
    logger.info(f"  â€¢ ìµœê·¼ 24ì‹œê°„: {len(analysis['recent_news'])}ê°œ")
    
    if analysis['sources']:
        logger.info(f"ğŸ“Š ë‰´ìŠ¤ ì†ŒìŠ¤:")
        for source, count in analysis['sources'].items():
            logger.info(f"  â€¢ {source}: {count}ê°œ")
    
    # ì²« ë²ˆì§¸ ë‰´ìŠ¤ì˜ ë³¸ë¬¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    if analysis['news_items']:
        first_news = analysis['news_items'][0]
        logger.info(f"\nğŸ“„ ì²« ë²ˆì§¸ ë‰´ìŠ¤ ìƒì„¸:")
        logger.info(f"  ì œëª©: {first_news['title']}")
        logger.info(f"  ì„¤ëª…: {first_news['description'][:100]}...")
        logger.info(f"  ì†ŒìŠ¤: {first_news['source']}")
        logger.info(f"  ë°œí–‰: {first_news['pub_date']}")
        
        # ë³¸ë¬¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
        content = api.collect_content(first_news['link'])
        logger.info(f"  ë³¸ë¬¸: {content[:200]}...")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ìƒ˜í”Œ ì €ì¥
        save_sample_news(stock_code, stock_name, first_news, content)

def save_sample_news(stock_code: str, stock_name: str, news_item: Dict, content: str):
    """ìƒ˜í”Œ ë‰´ìŠ¤ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    logger.info("ğŸ’¾ ìƒ˜í”Œ ë‰´ìŠ¤ ì €ì¥ ì¤‘...")
    
    db_path = "finance_data.db"
    
    try:
        with sqlite3.connect(db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO news_articles 
                (stock_code, stock_name, title, link, description, content, pub_date, source)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                stock_code,
                stock_name,
                news_item['title'],
                news_item['link'],
                news_item['description'],
                content,
                news_item['pub_date'],
                news_item['source']
            ))
            
            conn.commit()
            logger.info("âœ… ìƒ˜í”Œ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ")
            
    except Exception as e:
        logger.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("\n" + "="*60)
    print("ğŸš€ ë„¤ì´ë²„ ë‰´ìŠ¤ API ì—°ë™ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # 1. API ì¸ì¦ ì •ë³´ ì…ë ¥
    print("\nğŸ” ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
    client_id = input("Client ID: ").strip()
    client_secret = input("Client Secret: ").strip()
    
    if not client_id or not client_secret:
        logger.error("âŒ Client IDì™€ Secretì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    # 2. API ì—°ê²° í…ŒìŠ¤íŠ¸
    api = NaverNewsAPITest(client_id, client_secret)
    
    if not api.test_connection():
        logger.error("âŒ API ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¸ì¦ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # 3. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
    stocks = test_existing_database()
    
    # 4. ë‰´ìŠ¤ í…Œì´ë¸” ìƒì„±
    create_news_table()
    
    # 5. ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸
    print("\nğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    if stocks:
        # ê¸°ì¡´ ì¢…ëª©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        test_stock = stocks[0]  # ì²« ë²ˆì§¸ ì¢…ëª©
        test_news_collection(api, test_stock['code'], test_stock['name'])
    else:
        # ê¸°ë³¸ ì¢…ëª©ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        test_news_collection(api)
    
    # 6. ê²°ê³¼ í™•ì¸
    db_path = "finance_data.db"
    with sqlite3.connect(db_path) as conn:
        news_count = pd.read_sql_query(
            "SELECT COUNT(*) as count FROM news_articles", conn
        ).iloc[0]['count']
        
        if news_count > 0:
            recent_news = pd.read_sql_query("""
                SELECT stock_name, title, source, collected_at
                FROM news_articles 
                ORDER BY collected_at DESC 
                LIMIT 3
            """, conn)
            
            print(f"\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë°ì´í„°ë² ì´ìŠ¤ì— {news_count}ê°œ ë‰´ìŠ¤ ì €ì¥ë¨")
            print("\nğŸ“‹ ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤:")
            for _, news in recent_news.iterrows():
                print(f"  â€¢ [{news['source']}] {news['title'][:50]}...")
        else:
            print("\nâš ï¸ ë‰´ìŠ¤ê°€ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print("\nğŸš€ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰")
    print("  2. ê°ì • ë¶„ì„ ëª¨ë“ˆ ì¶”ê°€")
    print("  3. ìŠ¤ì¼€ì¤„ëŸ¬ë¡œ ìë™ ìˆ˜ì§‘ ì„¤ì •")

if __name__ == "__main__":
    main()