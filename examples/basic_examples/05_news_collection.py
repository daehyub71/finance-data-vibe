"""
ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ í¬ë¡¤ë§
2. ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ì§‘
3. ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
4. ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
5. ì¢…ëª©ë³„ ê°ì • ì§€ìˆ˜ ê³„ì‚°
6. ì‹œê³„ì—´ ê°ì • ì¶”ì´ ë¶„ì„

ë°ì´í„° ì†ŒìŠ¤:
- ë„¤ì´ë²„ ê¸ˆìœµ (finance.naver.com)
- ë‹¤ìŒ ê¸ˆìœµ (finance.daum.net)
- í•œêµ­ê²½ì œ (hankyung.com)

ğŸ¯ ëª©í‘œ: ë‰´ìŠ¤ ê¸°ë°˜ íˆ¬ì ì‹ í˜¸ ìƒì„±
"""

import sys
from pathlib import Path
import requests
from bs4 import BeautifulSoup
import pandas as pd
import sqlite3
import time
from datetime import datetime, timedelta
import re
import json
from urllib.parse import urljoin, quote
from tqdm import tqdm
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

try:
    from config.settings import DATA_DIR
    import warnings
    warnings.filterwarnings('ignore')
except ImportError as e:
    print(f"âŒ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”: {e}")
    exit(1)


class NewsCollector:
    """
    ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
    
    ì£¼ì‹ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë‹¤ì–‘í•œ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.data_dir = Path(DATA_DIR)
        self.db_path = self.data_dir / 'news_data.db'
        
        # ìˆ˜ì§‘ í†µê³„
        self.stats = {
            'total_collected': 0,
            'success_count': 0,
            'fail_count': 0,
            'duplicate_count': 0
        }
        
        # HTTP ì„¸ì…˜ ì„¤ì •
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        
        self.init_database()
        print("âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def init_database(self):
        """ğŸ—„ï¸ ë‰´ìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
        print("ğŸ—„ï¸ ë‰´ìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ë‰´ìŠ¤ ê¸°ì‚¬ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news_articles (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    stock_code TEXT,
                    stock_name TEXT,
                    title TEXT NOT NULL,
                    content TEXT,
                    summary TEXT,
                    url TEXT UNIQUE,
                    source TEXT,
                    author TEXT,
                    published_date TEXT,
                    collected_date TEXT,
                    sentiment_score REAL,
                    sentiment_label TEXT,
                    keywords TEXT,
                    view_count INTEGER,
                    comment_count INTEGER
                )
            ''')
            
            # ê°ì • ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS sentiment_analysis (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    stock_code TEXT NOT NULL,
                    date TEXT NOT NULL,
                    positive_count INTEGER DEFAULT 0,
                    negative_count INTEGER DEFAULT 0,
                    neutral_count INTEGER DEFAULT 0,
                    total_count INTEGER DEFAULT 0,
                    sentiment_score REAL DEFAULT 0,
                    sentiment_index REAL DEFAULT 50,
                    created_date TEXT,
                    UNIQUE(stock_code, date)
                )
            ''')
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ í…Œì´ë¸”
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS news_keywords (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    stock_code TEXT,
                    keyword TEXT,
                    frequency INTEGER,
                    date TEXT,
                    sentiment_impact REAL,
                    created_date TEXT
                )
            ''')
            
            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_stock_code ON news_articles(stock_code)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_news_published_date ON news_articles(published_date)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_sentiment_stock_date ON sentiment_analysis(stock_code, date)')
            
            conn.commit()
        
        print("âœ… ë‰´ìŠ¤ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def get_stock_list_from_db(self):
        """ğŸ“Š ì£¼ì‹ DBì—ì„œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        stock_db_path = self.data_dir / 'stock_data.db'
        
        if not stock_db_path.exists():
            print("âŒ ì£¼ì‹ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return []
        
        try:
            with sqlite3.connect(stock_db_path) as conn:
                query = """
                    SELECT DISTINCT symbol as stock_code, name as stock_name
                    FROM stock_info
                    WHERE symbol IS NOT NULL 
                    AND LENGTH(symbol) = 6
                    ORDER BY symbol
                """
                result = pd.read_sql_query(query, conn)
                return result.to_dict('records')
                
        except Exception as e:
            print(f"âŒ ì£¼ì‹ DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def collect_naver_finance_news(self, stock_code, stock_name, days=7, max_pages=5):
        """
        ğŸ“° ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘
        
        Args:
            stock_code (str): ì¢…ëª©ì½”ë“œ
            stock_name (str): ì¢…ëª©ëª…
            days (int): ìˆ˜ì§‘í•  ì¼ìˆ˜
            max_pages (int): ìµœëŒ€ í˜ì´ì§€ ìˆ˜
            
        Returns:
            list: ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        news_list = []
        
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ì¢…ëª© ë‰´ìŠ¤ URL
            base_url = f"https://finance.naver.com/item/news_news.naver"
            
            for page in range(1, max_pages + 1):
                params = {
                    'code': stock_code,
                    'page': page
                }
                
                try:
                    response = self.session.get(base_url, params=params, timeout=10)
                    response.raise_for_status()
                    
                    soup = BeautifulSoup(response.content, 'html.parser')
                    
                    # ë‰´ìŠ¤ ëª©ë¡ íŒŒì‹±
                    news_items = soup.select('.tb_cont tr')
                    
                    for item in news_items:
                        try:
                            # ì œëª©ê³¼ ë§í¬ ì¶”ì¶œ
                            title_elem = item.select_one('.title a')
                            if not title_elem:
                                continue
                            
                            title = title_elem.get_text(strip=True)
                            news_url = urljoin("https://finance.naver.com", title_elem.get('href'))
                            
                            # ë‚ ì§œ ì¶”ì¶œ
                            date_elem = item.select_one('.date')
                            if date_elem:
                                date_str = date_elem.get_text(strip=True)
                                published_date = self.parse_date(date_str)
                            else:
                                published_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            
                            # ì •ë³´ ì œê³µì ì¶”ì¶œ
                            info_elem = item.select_one('.info')
                            source = info_elem.get_text(strip=True) if info_elem else 'ë„¤ì´ë²„ê¸ˆìœµ'
                            
                            # ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ìˆ˜ì§‘
                            content, summary = self.get_news_content(news_url)
                            
                            news_data = {
                                'stock_code': stock_code,
                                'stock_name': stock_name,
                                'title': title,
                                'content': content,
                                'summary': summary,
                                'url': news_url,
                                'source': f'ë„¤ì´ë²„ê¸ˆìœµ-{source}',
                                'published_date': published_date,
                                'collected_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            }
                            
                            news_list.append(news_data)
                            
                            # ìš”ì²­ ê°„ê²© ì¡°ì ˆ
                            time.sleep(random.uniform(0.5, 1.5))
                            
                        except Exception as e:
                            print(f"  âš ï¸ ë‰´ìŠ¤ í•­ëª© íŒŒì‹± ì‹¤íŒ¨: {e}")
                            continue
                    
                    # í˜ì´ì§€ ê°„ ê°„ê²©
                    time.sleep(random.uniform(1, 2))
                    
                except Exception as e:
                    print(f"  âŒ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
        except Exception as e:
            print(f"âŒ {stock_code}({stock_name}) ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        return news_list
    
    def get_news_content(self, url):
        """
        ğŸ“„ ë‰´ìŠ¤ ìƒì„¸ ë‚´ìš© ì¶”ì¶œ
        
        Args:
            url (str): ë‰´ìŠ¤ URL
            
        Returns:
            tuple: (content, summary)
        """
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ë‹¤ì–‘í•œ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ì˜ ë³¸ë¬¸ ì„ íƒì
            content_selectors = [
                '.news_body',
                '.article_body',
                '.news_content',
                '#news_body',
                '.news_text',
                '.article_content',
                '#articleBodyContents'
            ]
            
            content = ""
            for selector in content_selectors:
                content_elem = soup.select_one(selector)
                if content_elem:
                    # ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼, ê´‘ê³  ë“± ì œê±°
                    for unwanted in content_elem.find_all(['script', 'style', 'iframe', 'ins']):
                        unwanted.decompose()
                    
                    content = content_elem.get_text(separator=' ', strip=True)
                    break
            
            # ìš”ì•½ ìƒì„± (ì²« 2ë¬¸ì¥)
            sentences = re.split(r'[.!?]\s+', content)
            summary = '. '.join(sentences[:2])[:200] if sentences else content[:200]
            
            return content, summary
            
        except Exception as e:
            return "", ""
    
    def parse_date(self, date_str):
        """ğŸ“… ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        try:
            # "07.05" í˜•íƒœ
            if re.match(r'\d{2}\.\d{2}', date_str):
                current_year = datetime.now().year
                month, day = date_str.split('.')
                return f"{current_year}-{month}-{day} 00:00:00"
            
            # "07.05 15:30" í˜•íƒœ
            elif re.match(r'\d{2}\.\d{2} \d{2}:\d{2}', date_str):
                current_year = datetime.now().year
                date_part, time_part = date_str.split(' ')
                month, day = date_part.split('.')
                return f"{current_year}-{month}-{day} {time_part}:00"
            
            # ê¸°íƒ€ í˜•íƒœëŠ” í˜„ì¬ ì‹œê°„ ë°˜í™˜
            else:
                return datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
        except:
            return datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    def save_news_to_db(self, news_list):
        """ğŸ“š ë‰´ìŠ¤ ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
        if not news_list:
            return 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                saved_count = 0
                for news in news_list:
                    try:
                        cursor.execute('''
                            INSERT OR IGNORE INTO news_articles 
                            (stock_code, stock_name, title, content, summary, url, source, 
                             published_date, collected_date)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            news.get('stock_code', ''),
                            news.get('stock_name', ''),
                            news.get('title', ''),
                            news.get('content', ''),
                            news.get('summary', ''),
                            news.get('url', ''),
                            news.get('source', ''),
                            news.get('published_date', ''),
                            news.get('collected_date', '')
                        ))
                        
                        if cursor.rowcount > 0:
                            saved_count += 1
                        else:
                            self.stats['duplicate_count'] += 1
                            
                    except Exception as e:
                        print(f"  âš ï¸ ë‰´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {e}")
                        continue
                
                conn.commit()
                return saved_count
                
        except Exception as e:
            print(f"âŒ ë‰´ìŠ¤ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0
    
    def collect_all_stock_news(self, days=7, max_stocks=None, max_workers=3):
        """
        ğŸš€ ëª¨ë“  ì¢…ëª©ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘
        
        Args:
            days (int): ìˆ˜ì§‘í•  ì¼ìˆ˜
            max_stocks (int): ìµœëŒ€ ì¢…ëª© ìˆ˜ (Noneì´ë©´ ì „ì²´)
            max_workers (int): ë™ì‹œ ì²˜ë¦¬ ìŠ¤ë ˆë“œ ìˆ˜
        """
        print("ğŸš€ ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘!")
        print("=" * 60)
        
        # ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        stock_list = self.get_stock_list_from_db()
        if not stock_list:
            print("âŒ ìˆ˜ì§‘í•  ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if max_stocks:
            stock_list = stock_list[:max_stocks]
        
        print(f"ğŸ“Š ì´ {len(stock_list)}ê°œ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜ˆì •")
        print(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: ìµœê·¼ {days}ì¼")
        print(f"ğŸ§µ ë™ì‹œ ì²˜ë¦¬: {max_workers}ê°œ ìŠ¤ë ˆë“œ")
        
        estimated_time = len(stock_list) * 30 / max_workers / 60  # ë¶„ ë‹¨ìœ„
        print(f"â±ï¸  ì˜ˆìƒ ì†Œìš”ì‹œê°„: ì•½ {estimated_time:.1f}ë¶„")
        
        confirm = input(f"\në‰´ìŠ¤ ìˆ˜ì§‘ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").strip().lower()
        if confirm != 'y':
            print("ğŸ‘‹ ìˆ˜ì§‘ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return
        
        # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ ìˆ˜ì§‘
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # ì‘ì—… ì œì¶œ
            future_to_stock = {}
            for stock in stock_list:
                future = executor.submit(
                    self.collect_stock_news_worker, 
                    stock['stock_code'], 
                    stock['stock_name'], 
                    days
                )
                future_to_stock[future] = stock
            
            # ì§„í–‰ë¥  í‘œì‹œ
            progress_bar = tqdm(
                as_completed(future_to_stock), 
                total=len(stock_list),
                desc="ğŸ“° ë‰´ìŠ¤ ìˆ˜ì§‘",
                unit="ì¢…ëª©"
            )
            
            for future in progress_bar:
                stock = future_to_stock[future]
                stock_code = stock['stock_code']
                stock_name = stock['stock_name']
                
                try:
                    news_count = future.result()
                    self.stats['success_count'] += 1
                    self.stats['total_collected'] += news_count
                    
                    progress_bar.set_postfix({
                        'Current': f"{stock_code}({stock_name[:8]})",
                        'News': self.stats['total_collected'],
                        'Success': self.stats['success_count']
                    })
                    
                except Exception as e:
                    self.stats['fail_count'] += 1
                    print(f"\nâŒ {stock_code}({stock_name}) ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ìˆ˜ì§‘ ê²°ê³¼ ì¶œë ¥
        self.print_collection_summary()
    
    def collect_stock_news_worker(self, stock_code, stock_name, days):
        """ğŸ“° ê°œë³„ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘ (ì›Œì»¤ í•¨ìˆ˜)"""
        try:
            # ë„¤ì´ë²„ ê¸ˆìœµ ë‰´ìŠ¤ ìˆ˜ì§‘
            news_list = self.collect_naver_finance_news(stock_code, stock_name, days)
            
            # DB ì €ì¥
            saved_count = self.save_news_to_db(news_list)
            
            return saved_count
            
        except Exception as e:
            raise e
    
    def print_collection_summary(self):
        """ğŸ“‹ ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ!")
        print("=" * 60)
        print(f"ğŸ“Š ì²˜ë¦¬ëœ ì¢…ëª©: {self.stats['success_count'] + self.stats['fail_count']:,}ê°œ")
        print(f"âœ… ì„±ê³µ: {self.stats['success_count']:,}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {self.stats['fail_count']:,}ê°œ")
        print(f"ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤: {self.stats['total_collected']:,}ê±´")
        print(f"ğŸ”„ ì¤‘ë³µ ì œì™¸: {self.stats['duplicate_count']:,}ê±´")
        print(f"ğŸ—„ï¸ ë°ì´í„° ì €ì¥: {self.db_path}")
        print("=" * 60)
    
    def query_db(self, query, params=None):
        """DB ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                if params:
                    return pd.read_sql_query(query, conn, params=params)
                else:
                    return pd.read_sql_query(query, conn)
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()
    
    def get_news_summary(self):
        """ğŸ“Š ë‰´ìŠ¤ ìˆ˜ì§‘ í˜„í™© ìš”ì•½"""
        print("ğŸ“Š ë‰´ìŠ¤ ìˆ˜ì§‘ í˜„í™©")
        print("=" * 40)
        
        # ì „ì²´ ë‰´ìŠ¤ ìˆ˜
        total_news = self.query_db("SELECT COUNT(*) as count FROM news_articles")
        print(f"ğŸ“° ì „ì²´ ë‰´ìŠ¤: {total_news.iloc[0]['count']:,}ê±´")
        
        # ì¢…ëª©ë³„ ë‰´ìŠ¤ ìˆ˜ (ìƒìœ„ 10ê°œ)
        stock_news = self.query_db("""
            SELECT stock_code, stock_name, COUNT(*) as news_count
            FROM news_articles
            GROUP BY stock_code, stock_name
            ORDER BY news_count DESC
            LIMIT 10
        """)
        
        if not stock_news.empty:
            print(f"\nğŸ“ˆ ì¢…ëª©ë³„ ë‰´ìŠ¤ (ìƒìœ„ 10ê°œ):")
            for _, row in stock_news.iterrows():
                print(f"   {row['stock_code']} ({row['stock_name']}): {row['news_count']}ê±´")
        
        # ì¼ë³„ ë‰´ìŠ¤ ìˆ˜ (ìµœê·¼ 7ì¼)
        daily_news = self.query_db("""
            SELECT DATE(published_date) as date, COUNT(*) as count
            FROM news_articles
            WHERE published_date >= DATE('now', '-7 days')
            GROUP BY DATE(published_date)
            ORDER BY date DESC
        """)
        
        if not daily_news.empty:
            print(f"\nğŸ“… ì¼ë³„ ë‰´ìŠ¤ (ìµœê·¼ 7ì¼):")
            for _, row in daily_news.iterrows():
                print(f"   {row['date']}: {row['count']}ê±´")
        
        print("=" * 40)


class NewsSentimentAnalyzer:
    """
    ë‰´ìŠ¤ ê°ì • ë¶„ì„ê¸°
    
    ìˆ˜ì§‘ëœ ë‰´ìŠ¤ì— ëŒ€í•´ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ì¢…ëª©ë³„ ê°ì • ì§€ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    
    def __init__(self):
        self.data_dir = Path(DATA_DIR)
        self.db_path = self.data_dir / 'news_data.db'
        
        # ê¸ˆìœµ ê°ì • ì‚¬ì „ (í•œêµ­ì–´)
        self.positive_words = {
            'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'ì„±ì¥', 'ì¦ê°€', 'í™•ëŒ€', 'ê°œì„ ', 'íšŒë³µ',
            'ëŒíŒŒ', 'ìƒí–¥', 'ê¸ì •', 'í˜¸í™©', 'í™œì„±', 'ë¶€ì–‘', 'íˆ¬ì', 'í™•ì¥',
            'ìˆ˜ìµ', 'ì´ìµ', 'ì‹¤ì ', 'ê°œë°œ', 'í˜ì‹ ', 'ì „ë§', 'ê¸°ëŒ€', 'ì¶”ì²œ',
            'ë§¤ìˆ˜', 'ê°•ì„¸', 'ë°˜ë“±', 'ì„ ë°©', 'ì–‘í˜¸', 'ìš°ìˆ˜', 'íƒ„íƒ„', 'ê²¬ì¡°'
        }
        
        self.negative_words = {
            'í•˜ë½', 'ê¸‰ë½', 'ì•…ì¬', 'ê°ì†Œ', 'ì¶•ì†Œ', 'ì•…í™”', 'ì¹¨ì²´', 'ìœ„ê¸°',
            'ì†ì‹¤', 'ì ì', 'ë¶€ì§„', 'ë‘”í™”', 'ê²½ê³ ', 'ìš°ë ¤', 'ë¶ˆì•ˆ', 'ë¦¬ìŠ¤í¬',
            'íƒ€ê²©', 'ì¶©ê²©', 'ì••ë°•', 'ì œì¬', 'ê·œì œ', 'íŒŒì‚°', 'êµ¬ì¡°ì¡°ì •',
            'ë§¤ë„', 'ì•½ì„¸', 'ì¡°ì •', 'ë¶€ë‹´', 'ì·¨ì•½', 'ì•…ìˆœí™˜', 'ì¹¨ì²´', 'ì €ì¡°'
        }
        
        print("âœ… ë‰´ìŠ¤ ê°ì • ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def calculate_sentiment_score(self, text):
        """
        ğŸ“Š í…ìŠ¤íŠ¸ ê°ì • ì ìˆ˜ ê³„ì‚°
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            tuple: (sentiment_score, sentiment_label)
                   sentiment_score: -1.0 ~ 1.0 (ë¶€ì • ~ ê¸ì •)
                   sentiment_label: 'positive', 'negative', 'neutral'
        """
        if not text:
            return 0.0, 'neutral'
        
        text = text.lower()
        
        # ê¸ì •/ë¶€ì • ë‹¨ì–´ ê°œìˆ˜ ê³„ì‚°
        positive_count = sum(1 for word in self.positive_words if word in text)
        negative_count = sum(1 for word in self.negative_words if word in text)
        
        # ì´ ê°ì • ë‹¨ì–´ ìˆ˜
        total_sentiment_words = positive_count + negative_count
        
        if total_sentiment_words == 0:
            return 0.0, 'neutral'
        
        # ê°ì • ì ìˆ˜ ê³„ì‚° (-1.0 ~ 1.0)
        sentiment_score = (positive_count - negative_count) / total_sentiment_words
        
        # ë¼ë²¨ ê²°ì •
        if sentiment_score > 0.2:
            sentiment_label = 'positive'
        elif sentiment_score < -0.2:
            sentiment_label = 'negative'
        else:
            sentiment_label = 'neutral'
        
        return sentiment_score, sentiment_label
    
    def analyze_all_news_sentiment(self):
        """ğŸ” ëª¨ë“  ë‰´ìŠ¤ì— ëŒ€í•´ ê°ì • ë¶„ì„ ìˆ˜í–‰"""
        print("ğŸ” ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹œì‘!")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ê°ì • ë¶„ì„ì´ ì•ˆëœ ë‰´ìŠ¤ë“¤ ì¡°íšŒ
                query = """
                    SELECT id, title, content, summary, stock_code
                    FROM news_articles
                    WHERE sentiment_score IS NULL
                    ORDER BY id
                """
                news_to_analyze = pd.read_sql_query(query, conn)
                
                if news_to_analyze.empty:
                    print("âœ… ëª¨ë“  ë‰´ìŠ¤ê°€ ì´ë¯¸ ê°ì • ë¶„ì„ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                    return
                
                print(f"ğŸ“Š ê°ì • ë¶„ì„ ëŒ€ìƒ: {len(news_to_analyze)}ê±´")
                
                cursor = conn.cursor()
                analyzed_count = 0
                
                # ì§„í–‰ë¥  í‘œì‹œ
                progress_bar = tqdm(news_to_analyze.iterrows(), 
                                  total=len(news_to_analyze),
                                  desc="ğŸ” ê°ì • ë¶„ì„",
                                  unit="ë‰´ìŠ¤")
                
                for _, row in progress_bar:
                    try:
                        # ì œëª©ê³¼ ìš”ì•½ì„ í•©ì³ì„œ ë¶„ì„
                        text_to_analyze = f"{row['title']} {row['summary']}"
                        
                        # ê°ì • ë¶„ì„ ìˆ˜í–‰
                        sentiment_score, sentiment_label = self.calculate_sentiment_score(text_to_analyze)
                        
                        # DB ì—…ë°ì´íŠ¸
                        cursor.execute('''
                            UPDATE news_articles 
                            SET sentiment_score = ?, sentiment_label = ?
                            WHERE id = ?
                        ''', (sentiment_score, sentiment_label, row['id']))
                        
                        analyzed_count += 1
                        
                        progress_bar.set_postfix({
                            'Analyzed': analyzed_count,
                            'Current': sentiment_label
                        })
                        
                    except Exception as e:
                        print(f"\nâš ï¸ ë‰´ìŠ¤ ID {row['id']} ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
                        continue
                
                conn.commit()
                
                print(f"\nâœ… ê°ì • ë¶„ì„ ì™„ë£Œ: {analyzed_count}ê±´")
                
                # ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½
                self.summarize_sentiment_results()
                
        except Exception as e:
            print(f"âŒ ê°ì • ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    def calculate_daily_sentiment_index(self):
        """ğŸ“ˆ ì¼ë³„ ì¢…ëª©ë³„ ê°ì • ì§€ìˆ˜ ê³„ì‚°"""
        print("ğŸ“ˆ ì¼ë³„ ê°ì • ì§€ìˆ˜ ê³„ì‚° ì¤‘...")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # ì¢…ëª©ë³„, ì¼ë³„ ê°ì • ë¶„ì„ ê²°ê³¼ ì§‘ê³„
                query = """
                    SELECT 
                        stock_code,
                        DATE(published_date) as date,
                        SUM(CASE WHEN sentiment_label = 'positive' THEN 1 ELSE 0 END) as positive_count,
                        SUM(CASE WHEN sentiment_label = 'negative' THEN 1 ELSE 0 END) as negative_count,
                        SUM(CASE WHEN sentiment_label = 'neutral' THEN 1 ELSE 0 END) as neutral_count,
                        COUNT(*) as total_count,
                        AVG(sentiment_score) as avg_sentiment_score
                    FROM news_articles
                    WHERE sentiment_score IS NOT NULL
                    AND published_date >= DATE('now', '-30 days')
                    GROUP BY stock_code, DATE(published_date)
                    ORDER BY stock_code, date
                """
                
                results = pd.read_sql_query(query, conn)
                
                if results.empty:
                    print("âŒ ê°ì • ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                # ê°ì • ì§€ìˆ˜ ê³„ì‚° ë° ì €ì¥
                for _, row in results.iterrows():
                    # ê°ì • ì§€ìˆ˜ ê³„ì‚° (0~100, 50ì´ ì¤‘ë¦½)
                    if row['total_count'] > 0:
                        positive_ratio = row['positive_count'] / row['total_count']
                        negative_ratio = row['negative_count'] / row['total_count']
                        sentiment_index = 50 + (positive_ratio - negative_ratio) * 50
                    else:
                        sentiment_index = 50
                    
                    # DBì— ì €ì¥
                    cursor.execute('''
                        INSERT OR REPLACE INTO sentiment_analysis
                        (stock_code, date, positive_count, negative_count, neutral_count,
                         total_count, sentiment_score, sentiment_index, created_date)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                    ''', (
                        row['stock_code'],
                        row['date'],
                        row['positive_count'],
                        row['negative_count'],
                        row['neutral_count'],
                        row['total_count'],
                        row['avg_sentiment_score'],
                        sentiment_index,
                        datetime.now().isoformat()
                    ))
                
                conn.commit()
                print(f"âœ… {len(results)}ê±´ì˜ ì¼ë³„ ê°ì • ì§€ìˆ˜ ê³„ì‚° ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ ê°ì • ì§€ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    def summarize_sentiment_results(self):
        """ğŸ“Š ê°ì • ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                # ì „ì²´ ê°ì • ë¶„í¬
                sentiment_dist = pd.read_sql_query("""
                    SELECT 
                        sentiment_label,
                        COUNT(*) as count,
                        COUNT(*) * 100.0 / (SELECT COUNT(*) FROM news_articles WHERE sentiment_label IS NOT NULL) as percentage
                    FROM news_articles
                    WHERE sentiment_label IS NOT NULL
                    GROUP BY sentiment_label
                """, conn)
                
                print("\nğŸ“Š ì „ì²´ ê°ì • ë¶„í¬:")
                for _, row in sentiment_dist.iterrows():
                    print(f"   {row['sentiment_label']}: {row['count']:,}ê±´ ({row['percentage']:.1f}%)")
                
                # ì¢…ëª©ë³„ ê°ì • ì ìˆ˜ (ìƒìœ„/í•˜ìœ„ 5ê°œ)
                stock_sentiment = pd.read_sql_query("""
                    SELECT 
                        stock_code,
                        stock_name,
                        AVG(sentiment_score) as avg_sentiment,
                        COUNT(*) as news_count
                    FROM news_articles
                    WHERE sentiment_score IS NOT NULL
                    GROUP BY stock_code, stock_name
                    HAVING COUNT(*) >= 5
                    ORDER BY avg_sentiment DESC
                """, conn)
                
                if not stock_sentiment.empty:
                    print(f"\nğŸ“ˆ ì¢…ëª©ë³„ í‰ê·  ê°ì • ì ìˆ˜:")
                    print("   ğŸ” ìƒìœ„ 5ê°œ:")
                    for _, row in stock_sentiment.head().iterrows():
                        print(f"      {row['stock_code']} ({row['stock_name']}): {row['avg_sentiment']:.3f} ({row['news_count']}ê±´)")
                    
                    print("   ğŸ“‰ í•˜ìœ„ 5ê°œ:")
                    for _, row in stock_sentiment.tail().iterrows():
                        print(f"      {row['stock_code']} ({row['stock_name']}): {row['avg_sentiment']:.3f} ({row['news_count']}ê±´)")
                
        except Exception as e:
            print(f"âš ï¸ ê°ì • ë¶„ì„ ìš”ì•½ ì‹¤íŒ¨: {e}")
    
    def get_stock_sentiment_trend(self, stock_code, days=30):
        """ğŸ“ˆ íŠ¹ì • ì¢…ëª©ì˜ ê°ì • ì¶”ì´ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = """
                    SELECT date, sentiment_index, total_count
                    FROM sentiment_analysis
                    WHERE stock_code = ?
                    AND date >= DATE('now', '-{} days')
                    ORDER BY date
                """.format(days)
                
                return pd.read_sql_query(query, conn, params=(stock_code,))
                
        except Exception as e:
            print(f"âŒ ê°ì • ì¶”ì´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸš€ Finance Data Vibe - ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    while True:
        print("\nğŸ“° ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘")
        print("2. íŠ¹ì • ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘")
        print("3. ë‰´ìŠ¤ ê°ì • ë¶„ì„ ìˆ˜í–‰")
        print("4. ì¼ë³„ ê°ì • ì§€ìˆ˜ ê³„ì‚°")
        print("5. ë‰´ìŠ¤ ìˆ˜ì§‘ í˜„í™© í™•ì¸")
        print("6. ê°ì • ë¶„ì„ ê²°ê³¼ í™•ì¸")
        print("0. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒí•˜ì„¸ìš” (0-6): ").strip()
        
        if choice == '0':
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        elif choice == '1':
            # ì „ì²´ ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘
            collector = NewsCollector()
            
            days = int(input("ìˆ˜ì§‘í•  ì¼ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 7): ").strip() or "7")
            max_stocks = input("ìµœëŒ€ ì¢…ëª© ìˆ˜ (ì „ì²´: Enter): ").strip()
            max_stocks = int(max_stocks) if max_stocks else None
            
            collector.collect_all_stock_news(days=days, max_stocks=max_stocks)
        
        elif choice == '2':
            # íŠ¹ì • ì¢…ëª© ë‰´ìŠ¤ ìˆ˜ì§‘
            collector = NewsCollector()
            
            stock_code = input("ì¢…ëª©ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 005930): ").strip()
            stock_name = input("ì¢…ëª©ëª…ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì‚¼ì„±ì „ì): ").strip()
            days = int(input("ìˆ˜ì§‘í•  ì¼ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ê¸°ë³¸ê°’: 7): ").strip() or "7")
            
            if stock_code and stock_name:
                news_list = collector.collect_naver_finance_news(stock_code, stock_name, days)
                saved_count = collector.save_news_to_db(news_list)
                print(f"âœ… {saved_count}ê±´ì˜ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
            else:
                print("âŒ ì¢…ëª©ì½”ë“œì™€ ì¢…ëª©ëª…ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        elif choice == '3':
            # ë‰´ìŠ¤ ê°ì • ë¶„ì„
            analyzer = NewsSentimentAnalyzer()
            analyzer.analyze_all_news_sentiment()
        
        elif choice == '4':
            # ì¼ë³„ ê°ì • ì§€ìˆ˜ ê³„ì‚°
            analyzer = NewsSentimentAnalyzer()
            analyzer.calculate_daily_sentiment_index()
        
        elif choice == '5':
            # ë‰´ìŠ¤ ìˆ˜ì§‘ í˜„í™©
            collector = NewsCollector()
            collector.get_news_summary()
        
        elif choice == '6':
            # ê°ì • ë¶„ì„ ê²°ê³¼
            analyzer = NewsSentimentAnalyzer()
            analyzer.summarize_sentiment_results()
        
        else:
            print("âŒ ì˜¬ë°”ë¥¸ ë²ˆí˜¸ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()